[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.uv]
index-strategy = "unsafe-best-match"
required-environments = [
    "sys_platform == 'win32' and platform_machine == 'AMD64'",
    "sys_platform == 'linux' and platform_machine == 'x86_64'",
    "sys_platform == 'darwin' and platform_machine == 'arm64'",
]
override-dependencies = [
    "nvidia-nccl-cu12; sys_platform == 'linux'",
]
default-groups = ["gpu"]

[[tool.uv.index]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cu128"
explicit = true


[[tool.uv.index]]
name = "pypi"
url = "https://pypi.org/simple"

[[tool.uv.index]]
name = "llama-cpp-metal"
url = "https://abetlen.github.io/llama-cpp-python/whl/metal/"
explicit = true

[[tool.uv.index]]
name = "llama-cpp-win-cpu"
url = "https://pnnbao97.github.io/llama-cpp-python-v0.3.16/cpu/"
explicit = true

[project]
name = "vieneu"
version = "1.2.3"
description = "Advanced on-device Vietnamese TTS with instant voice cloning"
readme = "README_PYPI.md"
license = { file = "LICENSE" }
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Multimedia :: Sound/Audio :: Speech",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Operating System :: OS Independent",
]
keywords = [
    "text-to-speech",
    "tts",
    "vietnamese",
    "voice-cloning",
    "speech-synthesis",
    "real-time",
    "on-device"
]
authors = [
    { name = "Phạm Nguyễn Ngọc Bảo", email = "pnnbao@gmail.com" }
]
requires-python = ">=3.10"
dependencies = [
    "phonemizer>=3.3.0",
    "neucodec>=0.0.4",
    "librosa>=0.11.0",
    "gradio>=5.49.1",
    "onnxruntime>=1.23.2",
    "datasets>=3.2.0",
    "torch",
    "torchaudio",
    "perth>=0.2.0",
    "llama-cpp-python==0.3.16",
    "requests",
]

[project.urls]
"Homepage" = "https://github.com/pnnbao97/VieNeu-TTS"
"Repository" = "https://github.com/pnnbao97/VieNeu-TTS"
"Bug Tracker" = "https://github.com/pnnbao97/VieNeu-TTS/issues"
"Documentation" = "https://github.com/pnnbao97/VieNeu-TTS/blob/main/README.md"
"Source Code" = "https://github.com/pnnbao97/VieNeu-TTS"
"Changelog" = "https://github.com/pnnbao97/VieNeu-TTS/releases"

[project.optional-dependencies]
gpu = [
    "lmdeploy; sys_platform != 'darwin'",
    "triton-windows; sys_platform == 'win32'",
    "triton; sys_platform == 'linux'",
    "transformers; sys_platform == 'darwin'",
    "accelerate; sys_platform == 'darwin'",
]

[dependency-groups]
dev = [
    "pytest",
    "pytest-asyncio",
]
gpu = [
    "lmdeploy; sys_platform != 'darwin'",
    "triton-windows; sys_platform == 'win32'",
    "triton; sys_platform == 'linux'",
    "transformers; sys_platform == 'darwin'",
    "accelerate; sys_platform == 'darwin'",
]

[tool.pytest.ini_options]
pythonpath = ["src"]

[project.scripts]
vieneu-web = "apps.gradio_main:main"
vieneu-stream = "apps.web_stream:main"

[tool.setuptools]
package-dir = {"" = "src", "apps" = "apps", "examples" = "examples"}

[tool.setuptools.packages.find]
where = ["src", "."]
include = ["vieneu*", "vieneu_utils*", "apps*", "examples*"]

[tool.setuptools.package-data]
vieneu_utils = ["*.json"]
vieneu = ["assets/samples/*"]

[tool.uv.sources]

torch = [
    { index = "pytorch", marker = "sys_platform != 'darwin'" },
    { index = "pypi", marker = "sys_platform == 'darwin'" }
]

torchaudio = [
    { index = "pytorch", marker = "sys_platform != 'darwin'" },
    { index = "pypi", marker = "sys_platform == 'darwin'" }
]

lmdeploy = [
    { url = "https://github.com/InternLM/lmdeploy/releases/download/v0.11.0/lmdeploy-0.11.0+cu128-cp312-cp312-win_amd64.whl", marker = "sys_platform == 'win32' and python_version == '3.12'" },
    { url = "https://github.com/InternLM/lmdeploy/releases/download/v0.11.0/lmdeploy-0.11.0+cu128-cp312-cp312-manylinux2014_x86_64.whl", marker = "sys_platform == 'linux' and python_version == '3.12'" },
    { index = "pypi", marker = "sys_platform == 'darwin'" }
]

llama-cpp-python = [
    { index = "llama-cpp-win-cpu", marker = "sys_platform == 'win32'" },
    { index = "llama-cpp-metal", marker = "sys_platform == 'darwin'" },
    { index = "pypi", marker = "sys_platform != 'win32' and sys_platform != 'darwin'" }
]
